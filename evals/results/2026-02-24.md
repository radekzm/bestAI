# Evals Report â€” 2026-02-24

Generated by: `bash evals/run.sh`

## Configuration
- tasks_file: `/root/bestAI/evals/tasks/benchmark_tasks.jsonl`
- input_dir: `/root/bestAI/evals/data`
- expected_tasks: 24

## Benchmark Set
| Category | Tasks |
|----------|------:|
| enforcement | 4 |
| memory | 4 |
| operations | 4 |
| runtime | 4 |
| smart-context | 4 |
| token-budget | 4 |

## Profile Metrics
| Profile | Runs | Coverage | Success % | Avg total tokens | Avg latency ms | P95 latency ms | Avg retries |
|---------|-----:|---------:|----------:|-----------------:|---------------:|---------------:|------------:|
| baseline | 24 | 100.00% | 83.33% | 2920.00 | 4075.00 | 4740.00 | 1.00 |
| hooks-only | 24 | 100.00% | 87.50% | 2592.50 | 3600.00 | 4170.00 | 0.50 |
| smart-context | 24 | 100.00% | 91.67% | 2312.50 | 3345.00 | 3896.00 | 0.50 |

## Delta vs baseline
| Profile | Success delta (pp) | Avg total tokens delta % | Avg latency delta % | Avg retries delta % |
|---------|-------------------:|-------------------------:|--------------------:|--------------------:|
| hooks-only | 4.17 | -11.22% | -11.66% | -50.00% |
| smart-context | 8.33 | -20.80% | -17.91% | -50.00% |

## Coverage Diagnostics
### baseline
- missing_tasks: 0
- extra_tasks: 0

### hooks-only
- missing_tasks: 0
- extra_tasks: 0

### smart-context
- missing_tasks: 0
- extra_tasks: 0

## Interpretation Guide
- Success up, retries down, latency stable/down => profile improvement
- Token reduction with stable success => context efficiency gain
- Success down with token down => over-compression/routing miss

## Schema Reminder
Each JSONL row should include: `task_id, success, input_tokens, output_tokens, latency_ms, retries`.
